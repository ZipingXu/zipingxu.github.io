
<table>

<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="guo2023online">1</a>]
</td>
<td class="bibtexitem">
Yongyi Guo, <strong>Ziping Xu</strong>, and Susan Murphy.
 Online learning in bandits with predicted context.
 <em>In Proceedings of the 27th International Conference on
  Artificial Intelligence and Statistics (AISTATS)</em>, 2024.
[&nbsp;<a href="https://proceedings.mlr.press/v238/guo24b/guo24b.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="Fan_2024_WACV">2</a>]
</td>
<td class="bibtexitem">
Quanfu Fan, Yilai Li, Yuguang Yao, John Cohn, Sijia Liu, <strong>Ziping Xu</strong>, Seychelle
  Vos, and Michael Cianfrocco.
 Cryorl: Reinforcement learning enables efficient cryo-em data
  collection.
 In <em>Proceedings of the IEEE/CVF Winter Conference on Applications
  of Computer Vision (WACV)</em>, pages 7892--7902, 2024.
[&nbsp;<a href="https://openaccess.thecvf.com/content/WACV2024/papers/Fan_CryoRL_Reinforcement_Learning_Enables_Efficient_Cryo-EM_Data_Collection_WACV_2024_paper.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="ICLR2024-Xu">3</a>]
</td>
<td class="bibtexitem">
<strong>Ziping Xu</strong>, Zifan Xu, Runxuan Jiang, Peter Stone, and Ambuj Tewari.
 Sample efficient myopic exploration through multitask reinforcement
  learning with diverse tasks.
 In <em>Proceedings of the International Conference on Learning
  Representations (ICLR)</em>, 2024.
[&nbsp;<a href="https://arxiv.org/pdf/2403.01636.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="xu2024fallacy">4</a>]
</td>
<td class="bibtexitem">
<strong>Ziping Xu</strong>, Kelly Zhang, and Susan Murphy.
 The fallacy of minimizing local regret in the sequential task
  setting.
 <em>arXiv</em>, 2024.
[&nbsp;<a href="https://arxiv.org/pdf/2403.10946">http</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="tan2024natural">5</a>]
</td>
<td class="bibtexitem">
Kevin Tan and <strong>Ziping Xu</strong>.
 A natural extension to online algorithms for hybrid rl with limited
  coverage.
 <em>Reinforcement Learning Journal</em>, 1, 2024.
[&nbsp;<a href="https://rlj.cs.umass.edu/2024/papers/Paper152.html">.html</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="xu2024adaptation">6</a>]
</td>
<td class="bibtexitem">
<strong>Ziping Xu</strong>, Iris Yan, and Susan Murphy.
 An adaptation of rlsvi with explicit action sampling probabilities.
 <em>RLC 2024 Deployable RL Workshop</em>, 2024.
[&nbsp;<a href="https://openreview.net/pdf?id=nn8u4ef0LH">http</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="xu2023coupling">7</a>]
</td>
<td class="bibtexitem">
<strong>Ziping Xu</strong>, Quanfu Fan, Yilai Li, Emma&nbsp;Rose Lee, John&nbsp;Maxwell Cohn, Ambuj
  Tewari, Seychelle&nbsp;M Vos, and Michael Cianfrocco.
 Coupling semi-supervised learning with reinforcement learning for
  better decision making---an application to cryo-em data collection.
 In <em>NeurIPS 2023 AI for Science Workshop</em>, 2023.
[&nbsp;<a href="https://openreview.net/pdf?id=kSqEwvApQy">http</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="shim2022predicting">8</a>]
</td>
<td class="bibtexitem">
Eunjae Shim, Joshua&nbsp;A Kammeraad, <strong>Ziping Xu</strong>, Ambuj Tewari, Tim Cernak, and
  Paul&nbsp;M Zimmerman.
 Predicting reaction conditions from limited data through active
  transfer learning.
 <em>Chemical Science</em>, 2022.
[&nbsp;<a href="https://pubs.rsc.org/en/content/articlepdf/2022/sc/d1sc06932b">http</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="sun2022supervised">9</a>]
</td>
<td class="bibtexitem">
Hao Sun, <strong>Ziping Xu</strong>, Taiyi Wang, Meng Fang, and Bolei Zhou.
 Supervised q-learning for continuous control.
 In <em>Deep Reinforcement Learning Workshop NeurIPS 2022</em>, 2022.
[&nbsp;<a href="https://openreview.net/pdf?id=fBDS6Xr__mg">http</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="sun2022mopa">10</a>]
</td>
<td class="bibtexitem">
Hao Sun, <strong>Ziping Xu</strong>, Zhenghao Peng, Meng Fang, Bo&nbsp;Dai, and Bolei Zhou.
 Mopa: a minimalist off-policy approach to safe-rl.
 In <em>Deep Reinforcement Learning Workshop NeurIPS 2022</em>, 2022.
[&nbsp;<a href="https://openreview.net/pdf?id=L86zZ6ow_WE">http</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="xu2022statistical">11</a>]
</td>
<td class="bibtexitem">
<strong>Ziping Xu</strong> and Ambuj Tewari.
 On the statistical benefits of curriculum learning.
 In <em>ICML</em>, pages 24663--24682. PMLR, 2022.
[&nbsp;<a href="https://proceedings.mlr.press/v162/xu22i/xu22i.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="xu2022adaptive">12</a>]
</td>
<td class="bibtexitem">
<strong>Ziping Xu</strong>, Eunjae Shim, Ambuj Tewari, and Paul Zimmerman.
 Adaptive sampling for discovery.
 In <em>NeurIPS</em>, 2022.
[&nbsp;<a href="https://arxiv.org/pdf/2205.14829">http</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="modi2022big">13</a>]
</td>
<td class="bibtexitem">
Aditya Modi, <strong>Ziping Xu</strong>, Mohamad&nbsp;KS Faradonbeh, and Ambuj Tewari.
 Big control actions help multitask learning of unstable linear
  systems.
 <em>In ICML 2022 Complex feedback in online learning Workshop</em>,
  2022.

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="Li_2022">14</a>]
</td>
<td class="bibtexitem">
Yilai Li, Quanfu Fan, <strong>Ziping Xu</strong>, Emma&nbsp;Rose Lee, John Cohn, Veronique Demers,
  Ja&nbsp;Young Lee, Lucy Yip, Michael&nbsp;A. Cianfrocco, and Seychelle&nbsp;M. Vos.
 Optimized path planning surpasses human efficiency in cryo-em
  imaging.
 <em>eLife</em>, 2022.
[&nbsp;<a href="http://dx.doi.org/10.1101/2022.06.17.496614">DOI</a>&nbsp;| 
<a href="http://dx.doi.org/10.1101/2022.06.17.496614">http</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="xu2021decision">15</a>]
</td>
<td class="bibtexitem">
<strong>Ziping Xu</strong>, Amirhossein Meisami, and Ambuj Tewari.
 Decision making problems with funnel structure: A multi-task learning
  approach with application to email marketing campaigns.
 In <em>AISTATS</em>, pages 127--135. PMLR, 2021.
[&nbsp;<a href="http://proceedings.mlr.press/v130/xu21a/xu21a.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="lu2021bandit">16</a>]
</td>
<td class="bibtexitem">
<strong>Ziping Xu</strong>, Yangyi Lu, and Ambuj Tewari.
 *bandit algorithms for precision medicine.
 <em>arXiv preprint arXiv:2108.04782</em>, 2021.
[&nbsp;<a href="https://download.arxiv.org/pdf/2108.04782v1">http</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="xu2021representation">17</a>]
</td>
<td class="bibtexitem">
<strong>Ziping Xu</strong> and Ambuj Tewari.
 Representation learning beyond linear prediction functions.
 <em>In NeurIPS</em>, 34:4792--4804, 2021.
[&nbsp;<a href="https://proceedings.neurips.cc/paper/2021/file/258be18e31c8188555c2ff05b4d542c3-Paper.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="xu2020meteorological">18</a>]
</td>
<td class="bibtexitem">
<strong>Ziping Xu</strong>, Song&nbsp;Xi Chen, and Xiaoqing Wu.
 Meteorological change and impacts on air pollution: Results from
  north china.
 <em>Journal of Geophysical Research: Atmospheres</em>,
  125(16):e2020JD032423, 2020.
[&nbsp;<a href="https://agupubs.onlinelibrary.wiley.com/doi/pdfdirect/10.1029/2020JD032423">http</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="xu2020reinforcement">19</a>]
</td>
<td class="bibtexitem">
<strong>Ziping Xu</strong> and Ambuj Tewari.
 Reinforcement learning in factored mdps: Oracle-efficient algorithms
  and tighter regret bounds for the non-episodic setting.
 <em>In NeurIPS</em>, 33:18226--18236, 2020.
[&nbsp;<a href="https://proceedings.neurips.cc/paper/2020/file/d3b1fb02964aa64e257f9f26a31f72cf-Paper.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="gogineni2020torsionnet">20</a>]
</td>
<td class="bibtexitem">
Tarun Gogineni, <strong>Ziping Xu</strong>, Exequiel Punzalan, Runxuan Jiang, Joshua Kammeraad,
  Ambuj Tewari, and Paul Zimmerman.
 Torsionnet: A reinforcement learning approach to sequential conformer
  search.
 <em>In NeurIPS</em>, 2020.
[&nbsp;<a href="https://proceedings.neurips.cc/paper/2020/file/e904831f48e729f9ad8355a894334700-Paper.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="xu2019worst">21</a>]
</td>
<td class="bibtexitem">
<strong>Ziping Xu</strong> and Ambuj Tewari.
 Worst-case regret bound for perturbation based exploration.
 <em>In NeurIPS</em>, 2019.
[&nbsp;<a href="https://optrl2019.github.io/assets/accepted_papers/24.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="liu2018health">22</a>]
</td>
<td class="bibtexitem">
Wenling Liu, <strong>Ziping Xu</strong>, and Tianan Yang.
 Health effects of air pollution in china.
 <em>International journal of environmental research and public
  health</em>, 15(7):1471, 2018.
[&nbsp;<a href="https://www.mdpi.com/1660-4601/15/7/1471">http</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="zhang2017cautionary">23</a>]
</td>
<td class="bibtexitem">
Shuyi Zhang, Bin Guo, Anlan Dong, Jing He, <strong>Ziping Xu</strong>, and Song&nbsp;Xi Chen.
 Cautionary tales on air-quality improvement in beijing.
 <em>Proceedings of the Royal Society A: Mathematical, Physical and
  Engineering Sciences</em>, 473(2205):20170457, 2017.
[&nbsp;<a href="https://royalsocietypublishing.org/doi/pdf/10.1098/rspa.2017.0457">http</a>&nbsp;]

</td>
</tr>
</table>